{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for File Access/Rescaling of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importLabels(filenameString):\n",
    "    import csv\n",
    "    import numpy as np\n",
    "    #Import manual scores\n",
    "    with open(filenameString, newline='') as csvfile:\n",
    "        manualScores = list(csv.reader(csvfile))\n",
    "    #Initialize\n",
    "    labels = []\n",
    "    l = len(manualScores) - 2\n",
    "\n",
    "    #Replaces all blank scores with zeros\n",
    "    count = 0\n",
    "    for i in manualScores:\n",
    "        count = count + 1\n",
    "        if count > 2:\n",
    "            if i[1] == '':\n",
    "                i[1] = 0\n",
    "\n",
    "    #Create separate list of scores\n",
    "    for j in range(l):\n",
    "        labels.append(manualScores[j+2][1])\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importPathnames(directoryString):\n",
    "    import os\n",
    "    pathnames = []\n",
    "    filenames = []\n",
    "\n",
    "    directory = os.fsencode(directoryString)\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        #Bubblesort to get pathnames in order\n",
    "        filenames.append(filename)\n",
    "        n = len(filenames) \n",
    "        # Traverse through all array elements\n",
    "        for i in range(n): \n",
    "        # Last i elements are already in place \n",
    "            for j in range(0, n-i-1): \n",
    "                sub1 = list(filenames[j])\n",
    "                sub2 = list(filenames[j+1])\n",
    "                # traverse the array from 0 to n-i-1 \n",
    "                # Swap if the element found is greater \n",
    "                # than the next element \n",
    "                if sub1[24:27] > sub2[24:27] : \n",
    "                    filenames[j], filenames[j+1] = filenames[j+1], filenames[j]\n",
    "\n",
    "    for i in filenames:    \n",
    "        pathname = directoryString + str(i)\n",
    "        pathnames.append(pathname) \n",
    "    return pathnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importFeatures(pathnames,labels):\n",
    "    #Imports features from csv files\n",
    "    features = []\n",
    "    #Get list of file names\n",
    "    for j in pathnames:\n",
    "        with open(str(j), newline='') as csvfile:\n",
    "                kinematics = list(csv.reader(csvfile))\n",
    "                kinematics = np.asarray(kinematics)\n",
    "                features.append(kinematics[3:,1:])\n",
    "    print(np.shape(features))\n",
    "    labels = labels[0:len(features)]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def scaleProb(features):\n",
    "    #Scale all coordinates by associated probability, save new features\n",
    "    #matrix as pScaledFeatures\n",
    "    \n",
    "    #INSTEAD: Go through data and cut out anything with a probability of <.90?\n",
    "    #But there will be entire frames where several but not all points have a\n",
    "    #high probability -- instead, omit frames where the cumulative probability of all points is low\n",
    "    pScaledFeatures = features\n",
    "    temp = np.empty([73,1291,32])\n",
    "    #All videos\n",
    "    icount = 0\n",
    "    for i in pScaledFeatures: \n",
    "        jcount = 0\n",
    "        #All frames\n",
    "        for j in i:\n",
    "            kcount = 0\n",
    "            sz = len(j)\n",
    "            #All features\n",
    "            sumprob = 0\n",
    "            for k in range(sz-1):\n",
    "                if ((k+1)%3) == 0:\n",
    "                    if float(j[k]) < 0.9:\n",
    "                        #print(float(j[k]))\n",
    "                        j[k-1] = 0\n",
    "                        j[k-2] = 0\n",
    "                    else:\n",
    "                        print(float(j[k]))\n",
    "                    #kcount = kcount+2\n",
    "            #jcount = jcount + 1\n",
    "            #print(np.shape(temp))\n",
    "        #icount = icount + 1\n",
    "    return temp\n",
    "\n",
    "#temp = scaleProb(features)\n",
    "#print(np.shape(features))\n",
    "#print(np.shape(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3 = np.empty([6,6,6])\n",
    "n, r, c = np.shape(temp3)\n",
    "for i in range(n):\n",
    "    for j in range(r):\n",
    "        for k in range(c):\n",
    "            temp3[i,j,k] = j\n",
    "            \n",
    "\n",
    "#print(temp3)\n",
    "def deleteRow(temp3):\n",
    "    n, r, c = np.shape(temp3)\n",
    "    print(temp3)\n",
    "    total= 0\n",
    "    for i in range(n):\n",
    "        #print(n)\n",
    "        #print(r)\n",
    "        #rint(c)\n",
    "        for j in range(r):\n",
    "            for k in range(c):\n",
    "                total= total + temp3[i,j,k]\n",
    "            print(total)\n",
    "            if total >18:\n",
    "                #print(i)\n",
    "                #print(j)\n",
    "                #print(k)\n",
    "                #temp3 = np.delete(temp3,j,1)\n",
    "                print(np.shape(temp3))\n",
    "                #temp3 = deleteRow(temp3) \n",
    "            total = 0\n",
    "    return temp3\n",
    "\n",
    "temp3 = deleteRow(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(pScaledFeatures):\n",
    "    #Scale all coordinates by max pixel value\n",
    "    maxPix = 551\n",
    "\n",
    "    normalizedFeatures = pScaledFeatures\n",
    "\n",
    "    for a in normalizedFeatures:\n",
    "        for b in a:\n",
    "            sz = len(b)\n",
    "            for c in range(sz-1):\n",
    "                b[c] = float(b[c])/551\n",
    "    return normalizedFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 1291, 48)\n"
     ]
    }
   ],
   "source": [
    "filenameString = 'R0186_20170815a_manualScores.csv'\n",
    "labels = importLabels(filenameString)\n",
    "directoryString = 'sampleData/R0186_20170815a/R0186_20170815a_direct/'\n",
    "pathnames = importPathnames(directoryString)\n",
    "features,labels = importFeatures(pathnames,labels)\n",
    "#pScaledFeatures = scaleProb(features)\n",
    "normalizedFeatures = normalize(features)\n",
    "#print(normalizedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do PCA on kinematics data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "redDimFeatures = np.empty([73,32])\n",
    "x = normalizedFeatures[0].transpose()\n",
    "x = np.asarray(x, dtype=float)\n",
    "pca = PCA(n_components=32)\n",
    "pca.fit(x)\n",
    "x = pca.transform(x)\n",
    "ycount = 0\n",
    "for y in normalizedFeatures:\n",
    "    y = y.transpose()\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    redDimFeatures[ycount] = pca.transform(y)[0] \n",
    "    ycount= ycount+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "\n",
    "#Train a random forest\n",
    "clf = MLP(solver='sgd', max_iter=10000)\n",
    "clf.fit(redDimFeatures, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1291, 48)\n"
     ]
    }
   ],
   "source": [
    "testFilenameString = 'R0189_20170924a_manualScores.csv'\n",
    "testlabels = importLabels(testFilenameString)\n",
    "directoryString = 'sampleData/R0189_20170924a/R0189_20170924a_direct/'\n",
    "pathnames = importPathnames(directoryString)\n",
    "testfeatures,testlabels = importFeatures(testpathnames,testlabels)\n",
    "#testpScaledFeatures = scaleProb(testfeatures)\n",
    "testNormalizedFeatures = normalize(testfeatures)\n",
    "testRedDim = np.empty([testl,32])\n",
    "ncount = 0\n",
    "for n in testNormalizedFeatures:\n",
    "    n = n.transpose()\n",
    "    n = np.asarray(n,dtype=float)\n",
    "    testRedDim[ncount] = pca.transform(n)[0]\n",
    "    ncount = ncount +1\n",
    "testOutput = clf.predict(testRedDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, '0', '1', '4', '1', '4', '4', '4', '4', '4', '7', '2', '4', '4', '4', '4', '4', '7', '4', '4', '4', '4', '4', '2', '4', '7', '2', '7', '7', '4', '4', '4', '7', '7', '3', '7', '7', '4', '7', '7', '4', '4', '4', '4', '4', '4', '4', '4']\n",
      "8\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(testlabels)\n",
    "\n",
    "points = 0\n",
    "for i in range(len(testlabels)):\n",
    "    if testlabels[i] == testOutput [i]:\n",
    "        points = points + 1\n",
    "        \n",
    "print(points)\n",
    "print(points/len(testlabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '4' '1' '1' '1' '1' '4' '1' '1' '4' '1' '4' '1' '1' '1' '1' '4' '1'\n",
      " '1' '1' '1' '4' '1' '1' '4' '4' '1' '1' '1' '1' '1' '1' '4' '1' '4' '1'\n",
      " '4' '1' '1' '1' '1' '1' '4' '1' '1' '4' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '4' '1' '1' '1' '1' '1' '1' '4' '1' '1' '1' '1' '1' '1' '1' '4'\n",
      " '1']\n",
      "(73,)\n"
     ]
    }
   ],
   "source": [
    "trainingOutput = clf.predict(redDimFeatures)\n",
    "print(output)\n",
    "print(np.shape(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, '1', '4', '4', '1', '1', '4', '1', '2', '4', '1', '4', '1', '1', '1', '4', '4', '1', '1', '1', '1', '4', '1', '1', '4', '4', 0, '4', '1', '1', '1', 0, '4', '1', '4', '1', '4', '1', '4', '4', 0, '1', '4', '1', '1', '4', '4', '1', '1', '1', '4', '1', 0, '4', '1', '1', '4', '1', '1', '4', 0, '1', '1', '4', '1', '1', 0, '3', '1', '4', '1', '2', '4']\n",
      "(73,)\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(np.shape(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "points = 0\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == trainingOutput [i]:\n",
    "        points = points + 1\n",
    "        \n",
    "print(points)\n",
    "print(points/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1291, 48)\n",
      "(48, 1291, 48)\n",
      "[0, '1', '4', '4', '1', '1', '4', '1', '2', '4', '1', '4', '1', '1', '1', '4', '4', '1', '1', '1', '1', '4', '1', '1', '4', '4', 0, '4', '1', '1', '1', 0, '4', '1', '4', '1', '4', '1', '4', '4', 0, '1', '4', '1', '1', '4', '4', '1']\n",
      "12\n",
      "0.25\n",
      "['0' '4' '1' '1' '1' '1' '4' '1' '1' '4' '1' '4' '1' '1' '1' '1' '4' '1'\n",
      " '1' '1' '1' '4' '1' '1' '4' '4' '1' '1' '1' '1' '1' '1' '4' '1' '4' '1'\n",
      " '4' '1' '1' '1' '1' '1' '4' '1' '1' '4' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '4' '1' '1' '1' '1' '1' '1' '4' '1' '1' '1' '1' '1' '1' '1' '4'\n",
      " '1']\n",
      "(73,)\n",
      "[0, '0', '1', '4', '1', '4', '4', '4', '4', '4', '7', '2', '4', '4', '4', '4', '4', '7', '4', '4', '4', '4', '4', '2', '4', '7', '2', '7', '7', '4', '4', '4', '7', '7', '3', '7', '7', '4', '7', '7', '4', '4', '4', '4', '4', '4', '4', '4']\n",
      "(48,)\n",
      "48\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "filenameString = 'R0189_20170924a_manualScores.csv'\n",
    "labels = importLabels(filenameString)\n",
    "vid, fram, feat = np.shape(normalizedFeatures)\n",
    "directoryString = 'sampleData/R0189_20170924a/R0189_20170924a_direct/'\n",
    "pathnames = importPathnames(directoryString)\n",
    "features,labels = importFeatures(pathnames,labels)\n",
    "#pScaledFeatures = scaleProb(features)\n",
    "normalizedFeatures = normalize(features)\n",
    "\n",
    "redDimFeatures = np.empty([vid,32])\n",
    "x = normalizedFeatures[0].transpose()\n",
    "x = np.asarray(x, dtype=float)\n",
    "pca2 = PCA(n_components=32)\n",
    "pca2.fit(x)\n",
    "x = pca2.transform(x)\n",
    "ycount = 0\n",
    "for y in normalizedFeatures:\n",
    "    y = y.transpose()\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    redDimFeatures[ycount] = pca2.transform(y)[0] \n",
    "    ycount= ycount+1\n",
    "    \n",
    "clf2 = MLP(solver='sgd', max_iter=10000)\n",
    "clf2.fit(redDimFeatures, labels)\n",
    "\n",
    "testFilenameString = 'R0186_20170815a_manualScores.csv'\n",
    "testlabels = importLabels(testFilenameString)\n",
    "vid2, fram2, feat2 = np.shape(normalizedFeatures)\n",
    "directoryString = 'sampleData/R0186_20170815a/R0186_20170815a_direct/'\n",
    "pathnames = importPathnames(directoryString)\n",
    "testfeatures,testlabels = importFeatures(testpathnames,testlabels)\n",
    "#testpScaledFeatures = scaleProb(testfeatures)\n",
    "testNormalizedFeatures = normalize(testfeatures)\n",
    "testRedDim = np.empty([vid2,32])\n",
    "ncount = 0\n",
    "for n in testNormalizedFeatures:\n",
    "    n = n.transpose()\n",
    "    n = np.asarray(n,dtype=float)\n",
    "    testRedDim[ncount] = pca2.transform(n)[0]\n",
    "    ncount = ncount +1\n",
    "testOutput = clf2.predict(testRedDim)\n",
    "\n",
    "print(testlabels)\n",
    "\n",
    "points = 0\n",
    "for i in range(len(testlabels)):\n",
    "    if int(testlabels[i]) == int(testOutput [i]):\n",
    "        points = points + 1\n",
    "        \n",
    "print(points)\n",
    "print(points/len(testlabels))\n",
    "\n",
    "trainingOutput = clf2.predict(redDimFeatures)\n",
    "print(output)\n",
    "print(np.shape(output))\n",
    "\n",
    "print(labels)\n",
    "print(np.shape(labels))\n",
    "\n",
    "points = 0\n",
    "for i in range(len(labels)):\n",
    "    if int(labels[i]) == int(trainingOutput[i]):\n",
    "        points = points + 1\n",
    "        \n",
    "print(points)\n",
    "print(points/len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Left View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 1291, 48)\n"
     ]
    }
   ],
   "source": [
    "filenameString = 'R0186_20170815a_manualScores.csv'\n",
    "labels = importLabels(filenameString)\n",
    "directoryString = 'sampleData/R0186_20170815a/R0186_20170815a_left/'\n",
    "pathnames = importPathnames(directoryString)\n",
    "features,labels = importFeatures(pathnames,labels)\n",
    "pScaledFeatures = scaleProb(features)\n",
    "normalizedFeatures = normalize(pScaledFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "\n",
    "#Train a random forest\n",
    "clf1 = MLP(solver='sgd', max_iter=10000)\n",
    "clf1.fit(redDimFeatures, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1291, 48)\n"
     ]
    }
   ],
   "source": [
    "testFilenameString = 'R0189_20170924a_manualScores.csv'\n",
    "testlabels = importLabels(testFilenameString)\n",
    "directoryString = 'sampleData/R0189_20170924a/R0189_20170924a_left/'\n",
    "pathnames = importPathnames(directoryString)\n",
    "testfeatures,testlabels = importFeatures(testpathnames,testlabels)\n",
    "\n",
    "testNormalizedFeatures = normalize(testpScaledFeatures)\n",
    "testRedDim = np.empty([testl,32])\n",
    "ncount = 0\n",
    "for n in testNormalizedFeatures:\n",
    "    n = n.transpose()\n",
    "    testRedDim[ncount] = pca.transform(n)[0]\n",
    "    ncount = ncount +1\n",
    "testOutput = clf1.predict(testRedDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, '0', '1', '4', '1', '4', '4', '4', '4', '4', '7', '2', '4', '4', '4', '4', '4', '7', '4', '4', '4', '4', '4', '2', '4', '7', '2', '7', '7', '4', '4', '4', '7', '7', '3', '7', '7', '4', '7', '7', '4', '4', '4', '4', '4', '4', '4', '4']\n",
      "2\n",
      "0.041666666666666664\n",
      "['0' '4' '1' '1' '1' '1' '4' '1' '1' '4' '1' '4' '1' '1' '1' '1' '4' '1'\n",
      " '1' '1' '1' '4' '1' '1' '4' '4' '1' '1' '1' '1' '1' '1' '4' '1' '4' '1'\n",
      " '4' '1' '1' '1' '1' '1' '4' '1' '1' '4' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '4' '1' '1' '1' '1' '1' '1' '4' '1' '1' '1' '1' '1' '1' '1' '4'\n",
      " '1']\n",
      "(73,)\n",
      "66\n",
      "0.9041095890410958\n"
     ]
    }
   ],
   "source": [
    "print(testlabels)\n",
    "\n",
    "points = 0\n",
    "for i in range(len(testlabels)):\n",
    "    if testlabels[i] == testOutput [i]:\n",
    "        points = points + 1\n",
    "        \n",
    "print(points)\n",
    "print(points/len(testlabels))\n",
    "\n",
    "trainingOutput = clf1.predict(redDimFeatures)\n",
    "print(output)\n",
    "print(np.shape(output))\n",
    "\n",
    "points = 0\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == trainingOutput [i]:\n",
    "        points = points + 1\n",
    "        \n",
    "print(points)\n",
    "print(points/73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
